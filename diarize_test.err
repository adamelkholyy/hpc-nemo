[NeMo W 2025-01-31 12:03:56 nemo_logging:393] /lustre/home/ae553/.local/lib/python3.11/site-packages/pyannote/audio/core/io.py:43: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
      torchaudio.set_audio_backend("soundfile")
    
[NeMo W 2025-01-31 12:03:56 nemo_logging:393] /lustre/home/ae553/.local/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_verification.py:43: UserWarning: torchaudio._backend.get_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
      backend = torchaudio.get_audio_backend()
    
WARNING:speechbrain.utils.torch_audio_backend:This version of torchaudio is old. SpeechBrain no longer tries using the torchaudio global backend mechanism in recipes, so if you encounter issues, update torchaudio.
INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]
INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []
[NeMo W 2025-01-31 12:03:57 nemo_logging:393] /lustre/home/ae553/.local/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_verification.py:45: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0
      from speechbrain.pretrained import (
    
[NeMo W 2025-01-31 12:03:57 nemo_logging:393] /lustre/home/ae553/.local/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_verification.py:53: UserWarning: torchaudio._backend.set_audio_backend has been deprecated. With dispatcher enabled, this function is no-op. You can remove the function call.
      torchaudio.set_audio_backend(backend)
    
[NeMo W 2025-01-31 12:03:57 nemo_logging:393] /lustre/home/ae553/.local/lib/python3.11/site-packages/pyannote/audio/tasks/segmentation/mixins.py:37: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.
      from torchaudio.backend.common import AudioMetaData
    
INFO:root: torch.version.cuda: 12.1
INFO:root: torch.cuda.is_available(): True
INFO:root: using: cuda
INFO:root: device count: 1
INFO:root: device 0: NVIDIA A100 80GB PCIe
Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.4.0. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../home/ae553/.cache/torch/whisperx-vad-segmentation.bin`
[NeMo W 2025-01-31 12:04:01 nemo_logging:393] /lustre/home/ae553/.local/lib/python3.11/site-packages/pyannote/audio/utils/reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.
    It can be re-enabled by calling
       >>> import torch
       >>> torch.backends.cuda.matmul.allow_tf32 = True
       >>> torch.backends.cudnn.allow_tf32 = True
    See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.
    
      warnings.warn(
    
[NeMo W 2025-01-31 12:04:28 nemo_logging:393] /lustre/home/ae553/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
      warnings.warn(
    
[NeMo W 2025-01-31 12:05:08 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: null
    emb_dir: null
    sample_rate: 16000
    num_spks: 2
    soft_label_thres: 0.5
    labels: null
    batch_size: 15
    emb_batch_size: 0
    shuffle: true
    
[NeMo W 2025-01-31 12:05:08 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath: null
    emb_dir: null
    sample_rate: 16000
    num_spks: 2
    soft_label_thres: 0.5
    labels: null
    batch_size: 15
    emb_batch_size: 0
    shuffle: false
    
[NeMo W 2025-01-31 12:05:08 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    emb_dir: null
    sample_rate: 16000
    num_spks: 2
    soft_label_thres: 0.5
    labels: null
    batch_size: 15
    emb_batch_size: 0
    shuffle: false
    seq_eval_mode: false
    
[NeMo W 2025-01-31 12:05:09 nemo_logging:393] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.
    Train config : 
    manifest_filepath: /manifests/ami_train_0.63.json,/manifests/freesound_background_train.json,/manifests/freesound_laughter_train.json,/manifests/fisher_2004_background.json,/manifests/fisher_2004_speech_sampled.json,/manifests/google_train_manifest.json,/manifests/icsi_all_0.63.json,/manifests/musan_freesound_train.json,/manifests/musan_music_train.json,/manifests/musan_soundbible_train.json,/manifests/mandarin_train_sample.json,/manifests/german_train_sample.json,/manifests/spanish_train_sample.json,/manifests/french_train_sample.json,/manifests/russian_train_sample.json
    sample_rate: 16000
    labels:
    - background
    - speech
    batch_size: 256
    shuffle: true
    is_tarred: false
    tarred_audio_filepaths: null
    tarred_shard_strategy: scatter
    augmentor:
      shift:
        prob: 0.5
        min_shift_ms: -10.0
        max_shift_ms: 10.0
      white_noise:
        prob: 0.5
        min_level: -90
        max_level: -46
        norm: true
      noise:
        prob: 0.5
        manifest_path: /manifests/noise_0_1_musan_fs.json
        min_snr_db: 0
        max_snr_db: 30
        max_gain_db: 300.0
        norm: true
      gain:
        prob: 0.5
        min_gain_dbfs: -10.0
        max_gain_dbfs: 10.0
        norm: true
    num_workers: 16
    pin_memory: true
    
[NeMo W 2025-01-31 12:05:09 nemo_logging:393] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). 
    Validation config : 
    manifest_filepath: /manifests/ami_dev_0.63.json,/manifests/freesound_background_dev.json,/manifests/freesound_laughter_dev.json,/manifests/ch120_moved_0.63.json,/manifests/fisher_2005_500_speech_sampled.json,/manifests/google_dev_manifest.json,/manifests/musan_music_dev.json,/manifests/mandarin_dev.json,/manifests/german_dev.json,/manifests/spanish_dev.json,/manifests/french_dev.json,/manifests/russian_dev.json
    sample_rate: 16000
    labels:
    - background
    - speech
    batch_size: 256
    shuffle: false
    val_loss_idx: 0
    num_workers: 16
    pin_memory: true
    
[NeMo W 2025-01-31 12:05:09 nemo_logging:393] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).
    Test config : 
    manifest_filepath: null
    sample_rate: 16000
    labels:
    - background
    - speech
    batch_size: 128
    shuffle: false
    test_loss_idx: 0
    
splitting manifest:   0%|          | 0/1 [00:00<?, ?it/s]splitting manifest: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]splitting manifest: 100%|██████████| 1/1 [00:01<00:00,  1.43s/it]
vad:   0%|          | 0/59 [00:00<?, ?it/s]vad:   2%|▏         | 1/59 [00:00<00:10,  5.66it/s]vad:   3%|▎         | 2/59 [00:00<00:09,  6.18it/s]vad:   5%|▌         | 3/59 [00:00<00:08,  6.79it/s]vad:   7%|▋         | 4/59 [00:00<00:07,  7.04it/s]vad:   8%|▊         | 5/59 [00:00<00:07,  7.19it/s]vad:  10%|█         | 6/59 [00:00<00:07,  7.28it/s]vad:  12%|█▏        | 7/59 [00:00<00:07,  7.34it/s]vad:  14%|█▎        | 8/59 [00:01<00:06,  7.29it/s]vad:  15%|█▌        | 9/59 [00:01<00:06,  7.34it/s]vad:  17%|█▋        | 10/59 [00:01<00:06,  7.37it/s]vad:  19%|█▊        | 11/59 [00:01<00:06,  7.40it/s]vad:  20%|██        | 12/59 [00:01<00:06,  7.41it/s]vad:  22%|██▏       | 13/59 [00:01<00:06,  7.43it/s]vad:  24%|██▎       | 14/59 [00:01<00:06,  7.44it/s]vad:  25%|██▌       | 15/59 [00:02<00:05,  7.46it/s]vad:  27%|██▋       | 16/59 [00:02<00:05,  7.47it/s]vad:  29%|██▉       | 17/59 [00:02<00:05,  7.46it/s]vad:  31%|███       | 18/59 [00:02<00:05,  7.47it/s]vad:  32%|███▏      | 19/59 [00:02<00:05,  7.46it/s]vad:  34%|███▍      | 20/59 [00:02<00:05,  7.46it/s]vad:  36%|███▌      | 21/59 [00:02<00:05,  7.58it/s]vad:  37%|███▋      | 22/59 [00:02<00:04,  8.00it/s]vad:  39%|███▉      | 23/59 [00:03<00:04,  8.37it/s]vad:  41%|████      | 24/59 [00:03<00:04,  8.66it/s]vad:  42%|████▏     | 25/59 [00:03<00:03,  8.84it/s]vad:  44%|████▍     | 26/59 [00:03<00:03,  8.99it/s]vad:  46%|████▌     | 27/59 [00:03<00:03,  9.11it/s]vad:  47%|████▋     | 28/59 [00:03<00:03,  9.20it/s]vad:  49%|████▉     | 29/59 [00:03<00:03,  9.24it/s]vad:  51%|█████     | 30/59 [00:03<00:03,  9.29it/s]vad:  53%|█████▎    | 31/59 [00:03<00:03,  9.32it/s]vad:  54%|█████▍    | 32/59 [00:04<00:02,  9.35it/s]vad:  56%|█████▌    | 33/59 [00:04<00:02,  9.35it/s]vad:  58%|█████▊    | 34/59 [00:04<00:02,  9.37it/s]vad:  59%|█████▉    | 35/59 [00:04<00:02,  9.38it/s]vad:  61%|██████    | 36/59 [00:04<00:02,  9.38it/s]vad:  63%|██████▎   | 37/59 [00:04<00:02,  9.39it/s]vad:  64%|██████▍   | 38/59 [00:04<00:02,  9.39it/s]vad:  66%|██████▌   | 39/59 [00:04<00:02,  9.39it/s]vad:  68%|██████▊   | 40/59 [00:04<00:02,  9.39it/s]vad:  69%|██████▉   | 41/59 [00:05<00:01,  9.39it/s]vad:  71%|███████   | 42/59 [00:05<00:01,  9.41it/s]vad:  73%|███████▎  | 43/59 [00:05<00:01,  9.40it/s]vad:  75%|███████▍  | 44/59 [00:05<00:01,  9.40it/s]vad:  76%|███████▋  | 45/59 [00:05<00:01,  9.39it/s]vad:  78%|███████▊  | 46/59 [00:05<00:01,  9.38it/s]vad:  80%|███████▉  | 47/59 [00:05<00:01,  9.39it/s]vad:  81%|████████▏ | 48/59 [00:05<00:01,  9.39it/s]vad:  83%|████████▎ | 49/59 [00:05<00:01,  9.39it/s]vad:  85%|████████▍ | 50/59 [00:05<00:00,  9.38it/s]vad:  86%|████████▋ | 51/59 [00:06<00:00,  9.38it/s]vad:  88%|████████▊ | 52/59 [00:06<00:00,  9.38it/s]vad:  90%|████████▉ | 53/59 [00:06<00:00,  9.38it/s]vad:  92%|█████████▏| 54/59 [00:06<00:00,  9.39it/s]vad:  93%|█████████▎| 55/59 [00:06<00:00,  9.38it/s]vad:  95%|█████████▍| 56/59 [00:06<00:00,  9.38it/s]vad:  97%|█████████▋| 57/59 [00:06<00:00,  9.38it/s]vad:  98%|█████████▊| 58/59 [00:06<00:00,  9.38it/s]vad: 100%|██████████| 59/59 [00:06<00:00,  8.61it/s]
generating preds:   0%|          | 0/1 [00:00<?, ?it/s]generating preds: 100%|██████████| 1/1 [00:15<00:00, 15.53s/it]                                                               creating speech segments:   0%|          | 0/1 [00:00<?, ?it/s]creating speech segments: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]creating speech segments: 100%|██████████| 1/1 [00:01<00:00,  1.49s/it]
[1/5] extract embeddings:   0%|          | 0/44 [00:00<?, ?it/s][1/5] extract embeddings:   7%|▋         | 3/44 [00:00<00:01, 25.14it/s][1/5] extract embeddings:  16%|█▌        | 7/44 [00:00<00:01, 28.96it/s][1/5] extract embeddings:  25%|██▌       | 11/44 [00:00<00:01, 30.20it/s][1/5] extract embeddings:  34%|███▍      | 15/44 [00:00<00:00, 30.64it/s][1/5] extract embeddings:  43%|████▎     | 19/44 [00:00<00:00, 30.91it/s][1/5] extract embeddings:  52%|█████▏    | 23/44 [00:00<00:00, 31.03it/s][1/5] extract embeddings:  61%|██████▏   | 27/44 [00:00<00:00, 31.11it/s][1/5] extract embeddings:  70%|███████   | 31/44 [00:01<00:00, 31.24it/s][1/5] extract embeddings:  80%|███████▉  | 35/44 [00:01<00:00, 31.33it/s][1/5] extract embeddings:  89%|████████▊ | 39/44 [00:01<00:00, 31.49it/s][1/5] extract embeddings:  98%|█████████▊| 43/44 [00:01<00:00, 31.75it/s][1/5] extract embeddings: 100%|██████████| 44/44 [00:01<00:00, 30.87it/s]
[2/5] extract embeddings:   0%|          | 0/52 [00:00<?, ?it/s][2/5] extract embeddings:   8%|▊         | 4/52 [00:00<00:01, 32.56it/s][2/5] extract embeddings:  15%|█▌        | 8/52 [00:00<00:01, 34.18it/s][2/5] extract embeddings:  23%|██▎       | 12/52 [00:00<00:01, 34.85it/s][2/5] extract embeddings:  31%|███       | 16/52 [00:00<00:01, 35.02it/s][2/5] extract embeddings:  38%|███▊      | 20/52 [00:00<00:00, 35.09it/s][2/5] extract embeddings:  46%|████▌     | 24/52 [00:00<00:00, 35.24it/s][2/5] extract embeddings:  54%|█████▍    | 28/52 [00:00<00:00, 35.28it/s][2/5] extract embeddings:  62%|██████▏   | 32/52 [00:00<00:00, 35.31it/s][2/5] extract embeddings:  69%|██████▉   | 36/52 [00:01<00:00, 35.34it/s][2/5] extract embeddings:  77%|███████▋  | 40/52 [00:01<00:00, 35.45it/s][2/5] extract embeddings:  85%|████████▍ | 44/52 [00:01<00:00, 35.50it/s][2/5] extract embeddings:  92%|█████████▏| 48/52 [00:01<00:00, 35.68it/s][2/5] extract embeddings: 100%|██████████| 52/52 [00:01<00:00, 35.04it/s][2/5] extract embeddings: 100%|██████████| 52/52 [00:01<00:00, 35.12it/s]
[3/5] extract embeddings:   0%|          | 0/64 [00:00<?, ?it/s][3/5] extract embeddings:   6%|▋         | 4/64 [00:00<00:01, 34.79it/s][3/5] extract embeddings:  12%|█▎        | 8/64 [00:00<00:01, 36.80it/s][3/5] extract embeddings:  19%|█▉        | 12/64 [00:00<00:01, 37.57it/s][3/5] extract embeddings:  25%|██▌       | 16/64 [00:00<00:01, 37.89it/s][3/5] extract embeddings:  31%|███▏      | 20/64 [00:00<00:01, 38.02it/s][3/5] extract embeddings:  38%|███▊      | 24/64 [00:00<00:01, 38.09it/s][3/5] extract embeddings:  44%|████▍     | 28/64 [00:00<00:00, 37.38it/s][3/5] extract embeddings:  50%|█████     | 32/64 [00:00<00:00, 37.42it/s][3/5] extract embeddings:  56%|█████▋    | 36/64 [00:00<00:00, 37.55it/s][3/5] extract embeddings:  62%|██████▎   | 40/64 [00:01<00:00, 37.71it/s][3/5] extract embeddings:  69%|██████▉   | 44/64 [00:01<00:00, 37.84it/s][3/5] extract embeddings:  75%|███████▌  | 48/64 [00:01<00:00, 37.99it/s][3/5] extract embeddings:  81%|████████▏ | 52/64 [00:01<00:00, 38.14it/s][3/5] extract embeddings:  88%|████████▊ | 56/64 [00:01<00:00, 38.09it/s][3/5] extract embeddings:  94%|█████████▍| 60/64 [00:01<00:00, 38.26it/s][3/5] extract embeddings: 100%|██████████| 64/64 [00:01<00:00, 37.38it/s][3/5] extract embeddings: 100%|██████████| 64/64 [00:01<00:00, 37.65it/s]
[4/5] extract embeddings:   0%|          | 0/85 [00:00<?, ?it/s][4/5] extract embeddings:   5%|▍         | 4/85 [00:00<00:02, 38.91it/s][4/5] extract embeddings:  11%|█         | 9/85 [00:00<00:01, 42.41it/s][4/5] extract embeddings:  16%|█▋        | 14/85 [00:00<00:01, 43.40it/s][4/5] extract embeddings:  22%|██▏       | 19/85 [00:00<00:01, 43.92it/s][4/5] extract embeddings:  28%|██▊       | 24/85 [00:00<00:01, 44.18it/s][4/5] extract embeddings:  34%|███▍      | 29/85 [00:00<00:01, 44.23it/s][4/5] extract embeddings:  40%|████      | 34/85 [00:00<00:01, 44.24it/s][4/5] extract embeddings:  46%|████▌     | 39/85 [00:00<00:01, 44.30it/s][4/5] extract embeddings:  52%|█████▏    | 44/85 [00:01<00:00, 44.37it/s][4/5] extract embeddings:  58%|█████▊    | 49/85 [00:01<00:00, 44.37it/s][4/5] extract embeddings:  64%|██████▎   | 54/85 [00:01<00:00, 44.35it/s][4/5] extract embeddings:  69%|██████▉   | 59/85 [00:01<00:00, 44.32it/s][4/5] extract embeddings:  75%|███████▌  | 64/85 [00:01<00:00, 44.26it/s][4/5] extract embeddings:  81%|████████  | 69/85 [00:01<00:00, 44.24it/s][4/5] extract embeddings:  87%|████████▋ | 74/85 [00:01<00:00, 43.39it/s][4/5] extract embeddings:  93%|█████████▎| 79/85 [00:01<00:00, 43.56it/s][4/5] extract embeddings:  99%|█████████▉| 84/85 [00:01<00:00, 43.76it/s][4/5] extract embeddings: 100%|██████████| 85/85 [00:01<00:00, 43.72it/s]
[5/5] extract embeddings:   0%|          | 0/128 [00:00<?, ?it/s][5/5] extract embeddings:   4%|▍         | 5/128 [00:00<00:02, 43.13it/s][5/5] extract embeddings:   8%|▊         | 10/128 [00:00<00:02, 46.61it/s][5/5] extract embeddings:  12%|█▏        | 15/128 [00:00<00:02, 47.88it/s][5/5] extract embeddings:  16%|█▌        | 20/128 [00:00<00:02, 48.49it/s][5/5] extract embeddings:  20%|█▉        | 25/128 [00:00<00:02, 48.55it/s][5/5] extract embeddings:  23%|██▎       | 30/128 [00:00<00:02, 48.76it/s][5/5] extract embeddings:  27%|██▋       | 35/128 [00:00<00:01, 48.93it/s][5/5] extract embeddings:  31%|███▏      | 40/128 [00:00<00:01, 49.08it/s][5/5] extract embeddings:  35%|███▌      | 45/128 [00:00<00:01, 49.18it/s][5/5] extract embeddings:  39%|███▉      | 50/128 [00:01<00:01, 49.25it/s][5/5] extract embeddings:  43%|████▎     | 55/128 [00:01<00:01, 49.29it/s][5/5] extract embeddings:  47%|████▋     | 60/128 [00:01<00:01, 49.31it/s][5/5] extract embeddings:  51%|█████     | 65/128 [00:01<00:01, 49.34it/s][5/5] extract embeddings:  55%|█████▍    | 70/128 [00:01<00:01, 49.32it/s][5/5] extract embeddings:  59%|█████▊    | 75/128 [00:01<00:01, 49.31it/s][5/5] extract embeddings:  62%|██████▎   | 80/128 [00:01<00:00, 49.27it/s][5/5] extract embeddings:  66%|██████▋   | 85/128 [00:01<00:00, 49.17it/s][5/5] extract embeddings:  70%|███████   | 90/128 [00:01<00:00, 49.20it/s][5/5] extract embeddings:  74%|███████▍  | 95/128 [00:01<00:00, 49.25it/s][5/5] extract embeddings:  78%|███████▊  | 100/128 [00:02<00:00, 49.06it/s][5/5] extract embeddings:  82%|████████▏ | 105/128 [00:02<00:00, 49.13it/s][5/5] extract embeddings:  86%|████████▌ | 110/128 [00:02<00:00, 48.94it/s][5/5] extract embeddings:  90%|████████▉ | 115/128 [00:02<00:00, 48.96it/s][5/5] extract embeddings:  94%|█████████▍| 120/128 [00:02<00:00, 48.80it/s][5/5] extract embeddings:  98%|█████████▊| 125/128 [00:02<00:00, 48.90it/s][5/5] extract embeddings: 100%|██████████| 128/128 [00:02<00:00, 48.64it/s]
clustering:   0%|          | 0/1 [00:00<?, ?it/s]clustering: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]clustering: 100%|██████████| 1/1 [00:01<00:00,  1.60s/it]
[NeMo W 2025-01-31 12:05:46 nemo_logging:393] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate
  0%|          | 0/1 [00:00<?, ?it/s]100%|██████████| 1/1 [00:00<00:00,  3.74it/s]100%|██████████| 1/1 [00:00<00:00,  3.73it/s]
[NeMo W 2025-01-31 12:05:48 nemo_logging:393] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate
[NeMo W 2025-01-31 12:05:48 nemo_logging:393] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate
[NeMo W 2025-01-31 12:05:49 nemo_logging:393] Check if each ground truth RTTMs were present in the provided manifest file. Skipping calculation of Diariazation Error Rate
[NeMo W 2025-01-31 12:05:49 nemo_logging:393] /lustre/home/ae553/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
      warnings.warn(
    
[NeMo W 2025-01-31 12:05:49 nemo_logging:393] /lustre/shared/easybuild/software/PyTorch/2.1.2-foss-2023a-CUDA-12.1.1/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
      return self.fget.__get__(instance, owner)()
    
--- Logging error ---
Traceback (most recent call last):
  File "/lustre/shared/easybuild/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/logging/__init__.py", line 1110, in emit
    msg = self.format(record)
          ^^^^^^^^^^^^^^^^^^^
  File "/lustre/shared/easybuild/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/logging/__init__.py", line 953, in format
    return fmt.format(record)
           ^^^^^^^^^^^^^^^^^^
  File "/lustre/shared/easybuild/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/logging/__init__.py", line 687, in format
    record.message = record.getMessage()
                     ^^^^^^^^^^^^^^^^^^^
  File "/lustre/shared/easybuild/software/Python/3.11.3-GCCcore-12.3.0/lib/python3.11/logging/__init__.py", line 377, in getMessage
    msg = msg % self.args
          ~~~~^~~~~~~~~~~
TypeError: not all arguments converted during string formatting
Call stack:
  File "/lustre/projects/Research_Project-T116269/nemo/diarize.py", line 223, in <module>
    labled_words = punct_model.predict(words_list, chunk_size=230)
  File "/lustre/home/ae553/.local/lib/python3.11/site-packages/deepmultilingualpunctuation/punctuationmodel.py", line 47, in predict
    result = self.pipe(text)
  File "/lustre/home/ae553/.local/lib/python3.11/site-packages/transformers/pipelines/token_classification.py", line 248, in __call__
    return super().__call__(inputs, **kwargs)
  File "/lustre/home/ae553/.local/lib/python3.11/site-packages/transformers/pipelines/base.py", line 1167, in __call__
    logger.warning_once(
  File "/lustre/home/ae553/.local/lib/python3.11/site-packages/transformers/utils/logging.py", line 329, in warning_once
    self.warning(*args, **kwargs)
Message: 'You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset'
Arguments: (<class 'UserWarning'>,)
